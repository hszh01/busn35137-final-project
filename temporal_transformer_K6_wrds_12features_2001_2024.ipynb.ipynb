{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d2c4ac",
   "metadata": {},
   "source": [
    "## Step 1: Load Data + Basic Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8760fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0) Imports + path ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"model_input_features_12f_2001_2024.parquet\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fab60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1932300, 16)\n",
      "columns: ['permno', 'month', 'ret_fwd', 'split', 'mktcap_z', 'log_mktcap_z', 'book_to_market_z', 'momentum_z', 'rev_1m_z', 'volatility_z', 'beta_z', 'roa_z', 'ni_over_at_z', 'investment_z', 'asset_growth_z', 'leverage_z']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>month</th>\n",
       "      <th>ret_fwd</th>\n",
       "      <th>split</th>\n",
       "      <th>mktcap_z</th>\n",
       "      <th>log_mktcap_z</th>\n",
       "      <th>book_to_market_z</th>\n",
       "      <th>momentum_z</th>\n",
       "      <th>rev_1m_z</th>\n",
       "      <th>volatility_z</th>\n",
       "      <th>beta_z</th>\n",
       "      <th>roa_z</th>\n",
       "      <th>ni_over_at_z</th>\n",
       "      <th>investment_z</th>\n",
       "      <th>asset_growth_z</th>\n",
       "      <th>leverage_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>-0.012658</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.157869</td>\n",
       "      <td>0.013525</td>\n",
       "      <td>-0.027821</td>\n",
       "      <td>0.439072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.023105</td>\n",
       "      <td>-0.797419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.008146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>2001-02-28</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.156870</td>\n",
       "      <td>0.014942</td>\n",
       "      <td>-0.027516</td>\n",
       "      <td>0.551295</td>\n",
       "      <td>-0.468295</td>\n",
       "      <td>-1.069425</td>\n",
       "      <td>-0.743954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>2001-03-31</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.157546</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>-0.029609</td>\n",
       "      <td>0.519111</td>\n",
       "      <td>0.276944</td>\n",
       "      <td>-1.089087</td>\n",
       "      <td>-0.731609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>2001-04-30</td>\n",
       "      <td>0.097436</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.155160</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>-0.035844</td>\n",
       "      <td>0.636299</td>\n",
       "      <td>0.535419</td>\n",
       "      <td>-1.077850</td>\n",
       "      <td>-0.811650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.008790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>2001-05-31</td>\n",
       "      <td>0.114953</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.156406</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>-0.031098</td>\n",
       "      <td>0.660769</td>\n",
       "      <td>-0.447603</td>\n",
       "      <td>-1.055489</td>\n",
       "      <td>-0.824151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno      month   ret_fwd  split  mktcap_z  log_mktcap_z  \\\n",
       "0   10001 2001-01-31 -0.012658  train -0.157869      0.013525   \n",
       "1   10001 2001-02-28  0.038462  train -0.156870      0.014942   \n",
       "2   10001 2001-03-31 -0.025000  train -0.157546      0.016448   \n",
       "3   10001 2001-04-30  0.097436  train -0.155160      0.010490   \n",
       "4   10001 2001-05-31  0.114953  train -0.156406      0.012822   \n",
       "\n",
       "   book_to_market_z  momentum_z  rev_1m_z  volatility_z    beta_z  roa_z  \\\n",
       "0         -0.027821    0.439072  0.000000     -1.023105 -0.797419    0.0   \n",
       "1         -0.027516    0.551295 -0.468295     -1.069425 -0.743954    0.0   \n",
       "2         -0.029609    0.519111  0.276944     -1.089087 -0.731609    0.0   \n",
       "3         -0.035844    0.636299  0.535419     -1.077850 -0.811650    0.0   \n",
       "4         -0.031098    0.660769 -0.447603     -1.055489 -0.824151    0.0   \n",
       "\n",
       "   ni_over_at_z  investment_z  asset_growth_z  leverage_z  \n",
       "0      0.129901           0.0             0.0   -0.008146  \n",
       "1      0.130449           0.0             0.0   -0.007248  \n",
       "2      0.127774           0.0             0.0   -0.009131  \n",
       "3      0.125295           0.0             0.0   -0.008790  \n",
       "4      0.124020           0.0             0.0   -0.005912  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1) Read data ---\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "print(\"shape:\", df.shape)\n",
    "print(\"columns:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc555f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1932300 entries, 0 to 1932299\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   permno            int64         \n",
      " 1   month             datetime64[ns]\n",
      " 2   ret_fwd           float64       \n",
      " 3   split             object        \n",
      " 4   mktcap_z          float32       \n",
      " 5   log_mktcap_z      float32       \n",
      " 6   book_to_market_z  float32       \n",
      " 7   momentum_z        float32       \n",
      " 8   rev_1m_z          float32       \n",
      " 9   volatility_z      float32       \n",
      " 10  beta_z            float32       \n",
      " 11  roa_z             float32       \n",
      " 12  ni_over_at_z      float32       \n",
      " 13  investment_z      float32       \n",
      " 14  asset_growth_z    float32       \n",
      " 15  leverage_z        float32       \n",
      "dtypes: datetime64[ns](1), float32(12), float64(1), int64(1), object(1)\n",
      "memory usage: 147.4+ MB\n",
      "\n",
      "#keys: ['permno', 'month']\n",
      "#features: 12\n",
      "feature cols: ['mktcap_z', 'log_mktcap_z', 'book_to_market_z', 'momentum_z', 'rev_1m_z', 'volatility_z', 'beta_z', 'roa_z', 'ni_over_at_z', 'investment_z', 'asset_growth_z', 'leverage_z']\n"
     ]
    }
   ],
   "source": [
    "# --- 2) Basic checks: types, key columns, feature columns ---\n",
    "df.info()\n",
    "\n",
    "\n",
    "df[\"month\"] = pd.to_datetime(df[\"month\"])\n",
    "\n",
    "key_cols = [\"permno\", \"month\"]\n",
    "target_col = \"ret_fwd\"\n",
    "feature_cols = [c for c in df.columns if c.endswith(\"_z\")]\n",
    "\n",
    "print(\"\\n#keys:\", key_cols)\n",
    "print(\"#features:\", len(feature_cols))\n",
    "print(\"feature cols:\", feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate (permno, month) rows: 0\n",
      "\n",
      "Top NA rates:\n",
      "permno              0.0\n",
      "month               0.0\n",
      "ret_fwd             0.0\n",
      "split               0.0\n",
      "mktcap_z            0.0\n",
      "log_mktcap_z        0.0\n",
      "book_to_market_z    0.0\n",
      "momentum_z          0.0\n",
      "rev_1m_z            0.0\n",
      "volatility_z        0.0\n",
      "beta_z              0.0\n",
      "roa_z               0.0\n",
      "ni_over_at_z        0.0\n",
      "investment_z        0.0\n",
      "asset_growth_z      0.0\n",
      "leverage_z          0.0\n",
      "dtype: float64\n",
      "\n",
      "Target ret_fwd summary:\n",
      "count    1.932300e+06\n",
      "mean     8.315928e-03\n",
      "std      1.714482e-01\n",
      "min     -9.936000e-01\n",
      "1%      -3.851090e-01\n",
      "5%      -2.041291e-01\n",
      "50%      4.419000e-03\n",
      "95%      2.163530e-01\n",
      "99%      5.037592e-01\n",
      "max      3.900000e+01\n",
      "Name: ret_fwd, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 3) Integrity checks: duplicates, missingness ---\n",
    "dup_n = df.duplicated(key_cols).sum()\n",
    "print(\"duplicate (permno, month) rows:\", dup_n)\n",
    "\n",
    "na_rate = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nTop NA rates:\")\n",
    "print(na_rate.head(20))\n",
    "\n",
    "print(\"\\nTarget ret_fwd summary:\")\n",
    "print(df[target_col].describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c004dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall month range: 2001-01-31 00:00:00 to 2024-11-30 00:00:00\n",
      "Unique permno: 20759\n",
      "\n",
      "Split summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_permno</th>\n",
       "      <th>min_month</th>\n",
       "      <th>max_month</th>\n",
       "      <th>n_months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>381679</td>\n",
       "      <td>11047</td>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>2024-11-30</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1223153</td>\n",
       "      <td>14662</td>\n",
       "      <td>2001-01-31</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>327468</td>\n",
       "      <td>8877</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_rows  n_permno  min_month  max_month  n_months\n",
       "split                                                   \n",
       "test    381679     11047 2021-01-31 2024-11-30        47\n",
       "train  1223153     14662 2001-01-31 2016-12-31       192\n",
       "val     327468      8877 2017-01-31 2020-12-31        48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split time order checks:\n",
      "train_max < val_min: True\n",
      "val_max < test_min: True\n"
     ]
    }
   ],
   "source": [
    "# --- 4) Time coverage + split checks ---\n",
    "print(\"\\nOverall month range:\", df[\"month\"].min(), \"to\", df[\"month\"].max())\n",
    "print(\"Unique permno:\", df[\"permno\"].nunique())\n",
    "\n",
    "if \"split\" in df.columns:\n",
    "    split_summary = df.groupby(\"split\").agg(\n",
    "        n_rows=(\"permno\", \"size\"),\n",
    "        n_permno=(\"permno\", \"nunique\"),\n",
    "        min_month=(\"month\", \"min\"),\n",
    "        max_month=(\"month\", \"max\"),\n",
    "        n_months=(\"month\", \"nunique\"),\n",
    "    )\n",
    "    print(\"\\nSplit summary:\")\n",
    "    display(split_summary)\n",
    "\n",
    "\n",
    "    if set([\"train\", \"val\", \"test\"]).issubset(set(df[\"split\"].unique())):\n",
    "        train_max = split_summary.loc[\"train\", \"max_month\"]\n",
    "        val_min = split_summary.loc[\"val\", \"min_month\"]\n",
    "        val_max = split_summary.loc[\"val\", \"max_month\"]\n",
    "        test_min = split_summary.loc[\"test\", \"min_month\"]\n",
    "        print(\"\\nSplit time order checks:\")\n",
    "        print(\"train_max < val_min:\", train_max < val_min)\n",
    "        print(\"val_max < test_min:\", val_max < test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636b4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero rate by feature:\n",
      "asset_growth_z      0.295309\n",
      "roa_z               0.148212\n",
      "investment_z        0.074031\n",
      "rev_1m_z            0.003720\n",
      "mktcap_z            0.000000\n",
      "log_mktcap_z        0.000000\n",
      "book_to_market_z    0.000000\n",
      "momentum_z          0.000000\n",
      "volatility_z        0.000000\n",
      "beta_z              0.000000\n",
      "ni_over_at_z        0.000000\n",
      "leverage_z          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# --- 5) How many zeros in each feature? (possible imputation artifact) ---\n",
    "zero_rate = (df[feature_cols] == 0).mean().sort_values(ascending=False)\n",
    "print(\"Zero rate by feature:\")\n",
    "print(zero_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05aae019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall outlier rates:\n",
      "pct_ret_gt_1       0.002118\n",
      "pct_ret_gt_2       0.000408\n",
      "pct_ret_gt_5       0.000040\n",
      "pct_ret_lt_-0.5    0.003803\n",
      "dtype: float64\n",
      "\n",
      "Outlier rates by split:\n",
      "       pct_ret_gt_1  pct_ret_gt_2  pct_ret_gt_5  pct_ret_lt_-0.5\n",
      "split                                                           \n",
      "test       0.002570      0.000642      0.000084         0.004802\n",
      "train      0.001917      0.000300      0.000017         0.003446\n",
      "val        0.002339      0.000541      0.000076         0.003970\n"
     ]
    }
   ],
   "source": [
    "# --- 6) ret_fwd outlier rates (overall + by split) ---\n",
    "def outlier_rates(s):\n",
    "    return pd.Series({\n",
    "        \"pct_ret_gt_1\": (s > 1).mean(),     # >100% monthly return\n",
    "        \"pct_ret_gt_2\": (s > 2).mean(),     # >200%\n",
    "        \"pct_ret_gt_5\": (s > 5).mean(),     # >500%\n",
    "        \"pct_ret_lt_-0.5\": (s < -0.5).mean()\n",
    "    })\n",
    "\n",
    "print(\"Overall outlier rates:\")\n",
    "print(outlier_rates(df[\"ret_fwd\"]))\n",
    "\n",
    "print(\"\\nOutlier rates by split:\")\n",
    "print(df.groupby(\"split\")[\"ret_fwd\"].apply(outlier_rates).unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1338b",
   "metadata": {},
   "source": [
    "## Step 2: Construct Sequence Samples with K=6 Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4308277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582b1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "\n",
    "df = df.sort_values([\"permno\", \"month\"]).reset_index(drop=True)\n",
    "\n",
    "X_all = df[feature_cols].to_numpy(dtype=np.float32)   \n",
    "y_all = df[\"ret_fwd\"].to_numpy(dtype=np.float32)      \n",
    "permno_all = df[\"permno\"].to_numpy(dtype=np.int64)\n",
    "month_all = df[\"month\"].to_numpy()                    \n",
    "split_all = df[\"split\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f42f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total centers: 1831112\n",
      "Example centers: [5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "def make_sequence_centers(permno_arr: np.ndarray, K: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return indices i such that rows [i-K+1, ..., i] belong to same permno.\n",
    "    Assumes data sorted by permno then month.\n",
    "    \"\"\"\n",
    "    n = len(permno_arr)\n",
    "    centers = []\n",
    "    start = 0\n",
    "    while start < n:\n",
    "        end = start\n",
    "        p = permno_arr[start]\n",
    "        while end < n and permno_arr[end] == p:\n",
    "            end += 1\n",
    "        \n",
    "        if end - start >= K:\n",
    "            centers.extend(range(start + K - 1, end))\n",
    "        start = end\n",
    "    return np.array(centers, dtype=np.int64)\n",
    "\n",
    "centers = make_sequence_centers(permno_all, K=K)\n",
    "print(\"Total centers:\", len(centers))\n",
    "print(\"Example centers:\", centers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e7b5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1151578 val: 316780 test: 362754\n",
      "train month range: 2001-06-30 00:00:00 to 2016-12-31 00:00:00\n",
      "val month range: 2017-01-31 00:00:00 to 2020-12-31 00:00:00\n",
      "test month range: 2021-01-31 00:00:00 to 2024-11-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "train_centers = centers[split_all[centers] == \"train\"]\n",
    "val_centers   = centers[split_all[centers] == \"val\"]\n",
    "test_centers  = centers[split_all[centers] == \"test\"]\n",
    "\n",
    "print(\"train:\", len(train_centers), \"val:\", len(val_centers), \"test:\", len(test_centers))\n",
    "print(\"train month range:\", df.loc[train_centers, \"month\"].min(), \"to\", df.loc[train_centers, \"month\"].max())\n",
    "print(\"val month range:\", df.loc[val_centers, \"month\"].min(), \"to\", df.loc[val_centers, \"month\"].max())\n",
    "print(\"test month range:\", df.loc[test_centers, \"month\"].min(), \"to\", df.loc[test_centers, \"month\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f975391",
   "metadata": {},
   "source": [
    "## Step 3: Temporal Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151578 316780 362754\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "X_all_t = torch.from_numpy(X_all)            \n",
    "y_all_t = torch.from_numpy(y_all)            \n",
    "\n",
    "class SeqDatasetXYFast(Dataset):\n",
    "    def __init__(self, centers_idx, X_all_t, y_all_t, K: int):\n",
    "        self.centers = torch.as_tensor(centers_idx, dtype=torch.long)\n",
    "        self.X_all_t = X_all_t\n",
    "        self.y_all_t = y_all_t\n",
    "        self.K = K\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.centers.numel()\n",
    "\n",
    "    def __getitem__(self, j):\n",
    "        i = int(self.centers[j])\n",
    "        x_seq = self.X_all_t[i - self.K + 1 : i + 1]  \n",
    "        y = self.y_all_t[i]                           \n",
    "        return x_seq, y\n",
    "\n",
    "train_ds_xy = SeqDatasetXYFast(train_centers, X_all_t, y_all_t, K)\n",
    "val_ds_xy   = SeqDatasetXYFast(val_centers,   X_all_t, y_all_t, K)\n",
    "test_ds_xy  = SeqDatasetXYFast(test_centers,  X_all_t, y_all_t, K)\n",
    "\n",
    "print(len(train_ds_xy), len(val_ds_xy), len(test_ds_xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae999c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_seq shape: torch.Size([6, 12])\n",
      "y: 0.02542399987578392\n",
      "first row feats: tensor([-0.1579,  0.0135, -0.0278,  0.4391,  0.0000, -1.0231, -0.7974,  0.0000,\n",
      "         0.1299,  0.0000,  0.0000, -0.0081])\n",
      "last row feats: tensor([-0.1549,  0.0073, -0.0343,  0.4853,  0.1869, -1.0103, -0.8459,  0.0000,\n",
      "         0.1219,  0.0000,  0.0000, -0.0046])\n"
     ]
    }
   ],
   "source": [
    "x_seq, y = train_ds_xy[0]\n",
    "print(\"x_seq shape:\", x_seq.shape)   \n",
    "print(\"y:\", float(y))\n",
    "print(\"first row feats:\", x_seq[0])\n",
    "print(\"last row feats:\", x_seq[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fbd632c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 0) Torch setup: device + seed ---\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2b14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1) Wrap dataset to only return (X, y) for faster training ---\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class XYWrapper(Dataset):\n",
    "    def __init__(self, base_ds):\n",
    "        self.base = base_ds\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y, *_ = self.base[idx]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "X_all_t = torch.from_numpy(X_all)          \n",
    "y_all_t = torch.from_numpy(y_all)          \n",
    "\n",
    "class SeqDatasetXYFast(Dataset):\n",
    "    def __init__(self, centers_idx, X_all_t, y_all_t, K: int):\n",
    "        self.centers = torch.as_tensor(centers_idx, dtype=torch.long)\n",
    "        self.X_all_t = X_all_t\n",
    "        self.y_all_t = y_all_t\n",
    "        self.K = K\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.centers.numel()\n",
    "\n",
    "    def __getitem__(self, j):\n",
    "        i = int(self.centers[j])\n",
    "        x_seq = self.X_all_t[i - self.K + 1 : i + 1]  \n",
    "        y = self.y_all_t[i]\n",
    "        return x_seq, y\n",
    "\n",
    "train_ds_xy = SeqDatasetXYFast(train_centers, X_all_t, y_all_t, K)\n",
    "val_ds_xy   = SeqDatasetXYFast(val_centers,   X_all_t, y_all_t, K)\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds_xy, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\")\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds_xy, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\")\n",
    ")\n",
    "\n",
    "BATCH_SIZE, NUM_WORKERS\n",
    "\n",
    "BATCH_SIZE, NUM_WORKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d51f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) Positional encoding (sin/cos) ---\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        K = x.size(1)\n",
    "        return x + self.pe[:, :K, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3) Temporal Transformer model ---\n",
    "class TemporalTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features: int,\n",
    "        seq_len: int,\n",
    "        d_model: int = 64,\n",
    "        n_heads: int = 4,\n",
    "        n_layers: int = 2,\n",
    "        dim_ff: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        pooling: str = \"last\",  \n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert pooling in (\"last\", \"mean\")\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.pooling = pooling\n",
    "\n",
    "        self.input_proj = nn.Linear(n_features, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model=d_model, max_len=seq_len)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            activation=\"gelu\",\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=n_layers)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, K, n_features)\n",
    "        h = self.input_proj(x)          # (B, K, d_model)\n",
    "        h = self.pos_enc(h)             # add positional encoding\n",
    "        h = self.encoder(h)             # (B, K, d_model)\n",
    "\n",
    "        if self.pooling == \"last\":\n",
    "            z = h[:, -1, :]             # (B, d_model)\n",
    "        else:\n",
    "            z = h.mean(dim=1)           # (B, d_model)\n",
    "\n",
    "        out = self.head(z).squeeze(-1)  # (B,)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d687a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Train / Eval utilities  ---\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def run_eval(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            preds = model(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "            bs = x.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            n += bs\n",
    "    return total_loss / n\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    use_amp = (scaler is not None)\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if use_amp:\n",
    "            with autocast():\n",
    "                preds = model(x)\n",
    "                loss = loss_fn(preds, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            preds = model(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fcd880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tong\\anaconda3\\envs\\imdb_nlp\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch preds shape: torch.Size([1024])\n",
      "\n",
      "Total model params: 105,153\n"
     ]
    }
   ],
   "source": [
    "# --- 5) Smoke test: one forward pass + 2-3 epochs baseline training ---\n",
    "K = 6\n",
    "model = TemporalTransformer(\n",
    "    n_features=len(feature_cols),\n",
    "    seq_len=K,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    dim_ff=256,\n",
    "    dropout=0.1,\n",
    "    pooling=\"last\",\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "x0, y0 = next(iter(train_loader))\n",
    "with torch.no_grad():\n",
    "    p0 = model(x0.to(device))\n",
    "print(\"batch preds shape:\", p0.shape)\n",
    "print(f\"\\nTotal model params: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 50/200  loss=0.023007\n",
      "batch 100/200  loss=0.028059\n",
      "batch 150/200  loss=0.029491\n",
      "batch 200/200  loss=0.023292\n"
     ]
    }
   ],
   "source": [
    "# (mini-train): run 200 batches to confirm training is moving\n",
    "\n",
    "model.train()\n",
    "max_batches = 200\n",
    "\n",
    "for b, (x, y) in enumerate(train_loader, start=1):\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    y = y.to(device, non_blocking=True)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if b % 50 == 0:\n",
    "        print(f\"batch {b}/{max_batches}  loss={loss.item():.6f}\")\n",
    "\n",
    "    if b >= max_batches:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f33a32e",
   "metadata": {},
   "source": [
    "## Step 4: full training with validation + early stopping (K=6 baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2577c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tong\\AppData\\Local\\Temp\\ipykernel_19596\\820442575.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if device.type == \"cuda\" else None\n",
      "C:\\Users\\Tong\\AppData\\Local\\Temp\\ipykernel_19596\\977623607.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01: train_loss=0.025029  val_loss=0.031643\n",
      "epoch 02: train_loss=0.024758  val_loss=0.031615\n",
      "epoch 03: train_loss=0.024704  val_loss=0.031624\n",
      "epoch 04: train_loss=0.024673  val_loss=0.031606\n",
      "epoch 05: train_loss=0.024643  val_loss=0.031605\n",
      "epoch 06: train_loss=0.024617  val_loss=0.031647\n",
      "epoch 07: train_loss=0.024591  val_loss=0.031622\n",
      "early stop\n",
      "best val: 0.03160587973733695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "scaler = GradScaler() if device.type == \"cuda\" else None\n",
    "EPOCHS = 20\n",
    "PATIENCE = 3\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "bad_epochs = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, scaler=scaler)\n",
    "    val_loss = run_eval(model, val_loader, loss_fn)\n",
    "\n",
    "    print(f\"epoch {epoch:02d}: train_loss={train_loss:.6f}  val_loss={val_loss:.6f}\")\n",
    "\n",
    "    if val_loss < best_val - 1e-6:\n",
    "        best_val = val_loss\n",
    "        bad_epochs = 0\n",
    "        torch.save(model.state_dict(), f\"temporal_transformer_K{K}.pt\")\n",
    "    else:\n",
    "        bad_epochs += 1\n",
    "        if bad_epochs >= PATIENCE:\n",
    "            print(\"early stop\")\n",
    "            break\n",
    "\n",
    "print(\"best val:\", best_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de4096",
   "metadata": {},
   "source": [
    "## Step 5: build test loader with meta, then predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362754, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10026</td>\n",
       "      <td>0.039958</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>2021-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10026</td>\n",
       "      <td>-0.007275</td>\n",
       "      <td>0.014551</td>\n",
       "      <td>2021-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10026</td>\n",
       "      <td>0.048271</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>2021-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>0.066642</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>2021-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>2021-05-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   permno    y_true    y_pred      month\n",
       "0   10026  0.039958  0.014404 2021-01-31\n",
       "1   10026 -0.007275  0.014551 2021-02-28\n",
       "2   10026  0.048271  0.014604 2021-03-31\n",
       "3   10026  0.066642  0.014501 2021-04-30\n",
       "4   10026 -0.003058  0.014580 2021-05-31"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1) build meta test dataset/loader\n",
    "permno_all_t = torch.from_numpy(permno_all.astype(np.int64))\n",
    "month_all_np = month_all\n",
    "\n",
    "class SeqDatasetWithMetaFast(Dataset):\n",
    "    def __init__(self, centers_idx, X_all_t, y_all_t, permno_all_t, month_all_np, K: int):\n",
    "        self.centers = np.asarray(centers_idx, dtype=np.int64)\n",
    "        self.X_all_t = X_all_t\n",
    "        self.y_all_t = y_all_t\n",
    "        self.permno_all_t = permno_all_t\n",
    "        self.month_all_np = month_all_np\n",
    "        self.K = K\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.centers.shape[0]\n",
    "\n",
    "    def __getitem__(self, j):\n",
    "        i = int(self.centers[j])\n",
    "        x_seq = self.X_all_t[i - self.K + 1 : i + 1]\n",
    "        y = self.y_all_t[i]\n",
    "        permno = self.permno_all_t[i]\n",
    "\n",
    "        m = self.month_all_np[i]  \n",
    "       \n",
    "        month_int = int(str(m)[:7].replace(\"-\", \"\"))\n",
    "\n",
    "        return x_seq, y, permno, month_int\n",
    "\n",
    "test_ds_meta = SeqDatasetWithMetaFast(test_centers, X_all_t, y_all_t, permno_all_t, month_all_np, K)\n",
    "test_loader = DataLoader(test_ds_meta, batch_size=4096, shuffle=False, num_workers=0,\n",
    "                         pin_memory=(device.type==\"cuda\"))\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(f\"temporal_transformer_K{K}.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "preds_list, ys_list, permnos, months = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, permno, month in test_loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        pred = model(x).detach().cpu().numpy()\n",
    "        preds_list.append(pred)\n",
    "        ys_list.append(y.numpy())\n",
    "        permnos.append(permno.numpy())\n",
    "        months.append(month)\n",
    "\n",
    "pred_test = pd.DataFrame({\n",
    "    \"permno\": np.concatenate(permnos),\n",
    "    \"month_yyyymm\": np.concatenate(months),\n",
    "    \"y_true\": np.concatenate(ys_list),\n",
    "    \"y_pred\": np.concatenate(preds_list),\n",
    "})\n",
    "\n",
    "pred_test[\"month\"] = pd.to_datetime(pred_test[\"month_yyyymm\"].astype(str) + \"01\") + pd.offsets.MonthEnd(0)\n",
    "pred_test = pred_test.drop(columns=[\"month_yyyymm\"])\n",
    "\n",
    "print(pred_test.shape)\n",
    "pred_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e9474",
   "metadata": {},
   "source": [
    "## Step 6: Monthly decile portfolios (equal-weighted) + long-short + Sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58718fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "months: 47\n",
      "mean long-short: 0.019358955\n",
      "t-stat (approx): 3.121737114384867\n",
      "annualized Sharpe: 1.5773861437476815\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>decile</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>long_short</th>\n",
       "      <th>long</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-31</th>\n",
       "      <td>0.040144</td>\n",
       "      <td>0.040651</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>0.035777</td>\n",
       "      <td>0.045560</td>\n",
       "      <td>0.068785</td>\n",
       "      <td>0.081641</td>\n",
       "      <td>0.098142</td>\n",
       "      <td>0.117480</td>\n",
       "      <td>0.156352</td>\n",
       "      <td>0.116208</td>\n",
       "      <td>0.156352</td>\n",
       "      <td>0.040144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-28</th>\n",
       "      <td>-0.049125</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.035247</td>\n",
       "      <td>0.038711</td>\n",
       "      <td>0.035201</td>\n",
       "      <td>0.045195</td>\n",
       "      <td>0.034574</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.034574</td>\n",
       "      <td>-0.049125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>-0.023750</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>0.025411</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>0.034955</td>\n",
       "      <td>0.031407</td>\n",
       "      <td>0.031447</td>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.014222</td>\n",
       "      <td>0.037972</td>\n",
       "      <td>0.014222</td>\n",
       "      <td>-0.023750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>-0.029970</td>\n",
       "      <td>-0.002281</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.019631</td>\n",
       "      <td>0.021530</td>\n",
       "      <td>0.031821</td>\n",
       "      <td>0.022705</td>\n",
       "      <td>0.037260</td>\n",
       "      <td>0.061772</td>\n",
       "      <td>0.091742</td>\n",
       "      <td>0.061772</td>\n",
       "      <td>-0.029970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-31</th>\n",
       "      <td>0.072508</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.007037</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>-0.032120</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>0.072508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "decile             1         2         3         4         5         6  \\\n",
       "month                                                                    \n",
       "2021-01-31  0.040144  0.040651  0.020047  0.035777  0.045560  0.068785   \n",
       "2021-02-28 -0.049125  0.003958  0.010909  0.030135  0.032239  0.035247   \n",
       "2021-03-31 -0.023750  0.001764  0.019775  0.025411  0.033760  0.034955   \n",
       "2021-04-30 -0.029970 -0.002281  0.011086  0.014452  0.019631  0.021530   \n",
       "2021-05-31  0.072508  0.035793  0.009192  0.015938  0.008194  0.000644   \n",
       "\n",
       "decile             7         8         9        10  long_short      long  \\\n",
       "month                                                                      \n",
       "2021-01-31  0.081641  0.098142  0.117480  0.156352    0.116208  0.156352   \n",
       "2021-02-28  0.038711  0.035201  0.045195  0.034574    0.083699  0.034574   \n",
       "2021-03-31  0.031407  0.031447  0.032469  0.014222    0.037972  0.014222   \n",
       "2021-04-30  0.031821  0.022705  0.037260  0.061772    0.091742  0.061772   \n",
       "2021-05-31  0.003270  0.003085  0.007037  0.040388   -0.032120  0.040388   \n",
       "\n",
       "decile         short  \n",
       "month                 \n",
       "2021-01-31  0.040144  \n",
       "2021-02-28 -0.049125  \n",
       "2021-03-31 -0.023750  \n",
       "2021-04-30 -0.029970  \n",
       "2021-05-31  0.072508  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tmp = pred_test.copy()\n",
    "\n",
    "# 1) assign deciles within each month by y_pred\n",
    "def assign_decile(s):\n",
    "    \n",
    "    r = s.rank(method=\"first\")\n",
    "    return pd.qcut(r, 10, labels=False) + 1  # 1..10\n",
    "\n",
    "tmp[\"decile\"] = tmp.groupby(\"month\")[\"y_pred\"].transform(assign_decile)\n",
    "\n",
    "# 2) compute equal-weighted realized returns by month x decile\n",
    "dec_ret = (\n",
    "    tmp.groupby([\"month\", \"decile\"])[\"y_true\"]\n",
    "    .mean()\n",
    "    .reset_index(name=\"ret\")\n",
    ")\n",
    "\n",
    "# 3) long-short (top - bottom) each month\n",
    "wide = dec_ret.pivot(index=\"month\", columns=\"decile\", values=\"ret\").sort_index()\n",
    "wide[\"long_short\"] = wide[10] - wide[1]\n",
    "wide[\"long\"] = wide[10]\n",
    "wide[\"short\"] = wide[1]\n",
    "\n",
    "# 4) summary stats\n",
    "ls = wide[\"long_short\"].dropna()\n",
    "mean_ls = ls.mean()\n",
    "std_ls = ls.std(ddof=1)\n",
    "sharpe_ann = (mean_ls / std_ls) * np.sqrt(12)\n",
    "\n",
    "tstat = mean_ls / (std_ls / np.sqrt(ls.shape[0]))\n",
    "\n",
    "print(\"months:\", ls.shape[0])\n",
    "print(\"mean long-short:\", mean_ls)\n",
    "print(\"t-stat (approx):\", tstat)\n",
    "print(\"annualized Sharpe:\", sharpe_ann)\n",
    "\n",
    "wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3103d5e",
   "metadata": {},
   "source": [
    "## Step 7: OOS R^2 on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE: 0.0409826\n",
      "test OOS R^2: -0.0023403167724609375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y = pred_test[\"y_true\"].to_numpy()\n",
    "yhat = pred_test[\"y_pred\"].to_numpy()\n",
    "\n",
    "ss_res = np.sum((y - yhat) ** 2)\n",
    "ss_tot = np.sum((y - y.mean()) ** 2)\n",
    "oos_r2 = 1.0 - ss_res / ss_tot\n",
    "\n",
    "mse = np.mean((y - yhat) ** 2)\n",
    "\n",
    "print(\"test MSE:\", mse)\n",
    "print(\"test OOS R^2:\", oos_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be06a3b0",
   "metadata": {},
   "source": [
    "## Step 8: summarize results + export for group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9249fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_mse</th>\n",
       "      <th>test_oos_r2</th>\n",
       "      <th>ls_mean</th>\n",
       "      <th>ls_tstat</th>\n",
       "      <th>ls_sharpe_ann</th>\n",
       "      <th>n_test_months</th>\n",
       "      <th>n_test_obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TemporalTransformer_K6</td>\n",
       "      <td>0.040983</td>\n",
       "      <td>-0.00234</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>3.121737</td>\n",
       "      <td>1.577386</td>\n",
       "      <td>47</td>\n",
       "      <td>362754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  test_mse  test_oos_r2   ls_mean  ls_tstat  \\\n",
       "0  TemporalTransformer_K6  0.040983     -0.00234  0.019359  3.121737   \n",
       "\n",
       "   ls_sharpe_ann  n_test_months  n_test_obs  \n",
       "0       1.577386             47      362754  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = pd.DataFrame([{\n",
    "    \"model\": f\"TemporalTransformer_K{K}\",\n",
    "    \"test_mse\": float(mse),\n",
    "    \"test_oos_r2\": float(oos_r2),\n",
    "    \"ls_mean\": float(mean_ls),\n",
    "    \"ls_tstat\": float(tstat),\n",
    "    \"ls_sharpe_ann\": float(sharpe_ann),\n",
    "    \"n_test_months\": int(ls.shape[0]),\n",
    "    \"n_test_obs\": int(pred_test.shape[0]),\n",
    "}])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2ddcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: pred_test_transformer_K6.csv ls_portfolio_monthly_transformer_K6.csv summary_transformer_K6.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_test.to_csv(f\"pred_test_transformer_K{K}.csv\", index=False)\n",
    "wide.reset_index().to_csv(f\"ls_portfolio_monthly_transformer_K{K}.csv\", index=False)\n",
    "results.to_csv(f\"summary_transformer_K{K}.csv\", index=False)\n",
    "\n",
    "print(\"saved:\",\n",
    "      f\"pred_test_transformer_K{K}.csv\",\n",
    "      f\"ls_portfolio_monthly_transformer_K{K}.csv\",\n",
    "      f\"summary_transformer_K{K}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imdb_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
